{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Zona em que são definidos os imports necessários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import itertools\n",
    "import nltk\n",
    "import collections\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import util\n",
    "import nltk.classify\n",
    "from nltk.classify import maxent, naivebayes, svm\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função com as métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred):\n",
    "    \n",
    "    print(\"True positives: {}\".format(true_positive))\n",
    "    print(\"True Negatives: {}\".format(true_negative))\n",
    "    print(\"False Positives: {}\".format(false_positive))\n",
    "    print(\"False Negatives: {}\".format(false_negative))\n",
    "\n",
    "    print(\"\\nTweets Positivos: {}\".format(pos_real))\n",
    "    print(\"Tweets Positivos preditados: {}\".format(pos_pred))\n",
    "    print(\"Tweets Negativos: {}\".format(neg_real))\n",
    "    print(\"Tweets Negativos preditados: {}\".format(neg_pred))\n",
    "    \n",
    "    print(\"\\nPredicoes:\")\n",
    "    print(\"\\tPredicoes correctas: {}\".format(true_positive + true_negative))\n",
    "    print(\"\\tPredicoes erradas: {}\".format(false_negative + false_positive))\n",
    "    \n",
    "    accuracy = (true_positive + true_negative)/(true_positive + true_negative+false_negative + false_positive)*100\n",
    "    precision = true_positive/(true_positive+false_positive)*100\n",
    "    recall = true_positive/(true_positive+false_negative)*100\n",
    "    f1 = (2 * precision * recall)/(precision  + recall)\n",
    "\n",
    "    print(\"\\nMetricas:\")\n",
    "    print(\"\\tAccuracy: {}\".format(accuracy))\n",
    "    print(\"\\tPrecision: {}\".format(precision))\n",
    "    print(\"\\tRecall: {}\".format(recall))\n",
    "    print(\"\\tF-Measure: {}\".format(f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos dados e criação de uma baseline\n",
    "\n",
    "O conjunto de dados escolhido foi o \"Tweets_EN_sentiment.json\".\n",
    "Nesta fase iremos realizar a preparação dos dados e a criação de uma baseline, para que se possa comparar resultados posteriores.\n",
    "Foi detectado um desbalanceamento dos dados, na qual existem muito mais tweets positivos do que negativos, o que provocaria resultados desajustados à realidade, por exemplo: classificar todos os tweets de teste como sendo positivos e e por isso obter resultados com percentagens bastante elevadas, pelo facto de existirem mais tweets positivos do que negativos.\n",
    "Portanto foram usados todos os tweets negativos, que estão em menor número, e foram o número de tweets positivos igual ao número de tweets negativos.\n",
    "De forma a ter um conjunto de dados completamente aleatório em tipo de sentimentos, foram baralhados os dados de igual forma.\n",
    "Ir-se-á utilizar as primeiras linhas, 80% mais propriamente, para treino e as últimas para teste, neste caso as restantes 20%. A ferramenta utilizada para fazer Análise de Sentimento diretamente aos tweets foi o TextBlob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_unbalanced = []\n",
    "for tweet in open(\"../TM/data/en/Tweets_EN_sentiment.json\", \"r\"):\n",
    "    tweets_unbalanced.append(json.loads(tweet))\n",
    "\n",
    "count_neg = 0\n",
    "for tweet in tweets_unbalanced:\n",
    "    if tweet[\"class\"] == \"neg\":\n",
    "        count_neg += 1\n",
    "\n",
    "tweets = []\n",
    "count_pos = 0\n",
    "count_neg_equal = 0\n",
    "for tweet in tweets_unbalanced:\n",
    "    number_tweet = tweet['tweet']\n",
    "    text = tweet[\"text\"]\n",
    "    sentiment = tweet[\"class\"]\n",
    "    if tweet[\"class\"] == \"neg\" and count_neg != count_neg_equal:\n",
    "        count_neg_equal += 1\n",
    "        tweet = {'tweet': number_tweet,'text': text, 'class': sentiment}\n",
    "        tweets.append(tweet)\n",
    "    if tweet[\"class\"] == \"pos\" and count_pos < count_neg:\n",
    "        count_pos += 1\n",
    "        tweet = {'tweet': number_tweet, 'text': text, 'class': sentiment}\n",
    "        tweets.append(tweet)\n",
    "        \n",
    "random.shuffle(tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi criada uma lista de treino com 80% dos dados e uma lista de teste com os 20% restantes.\n",
    "Para além disso verificou-se quantos tweets positivos e negativos foram utilizados para treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fase inicial ---\n",
      "\n",
      "Tweets totais : 17088\n",
      "\n",
      "Treino:\n",
      "\tPositivos: 6795\n",
      "\tNegativos: 6875\n",
      "\tTotal: 13670\n",
      "\n",
      "Teste:\n",
      "\tPositivos: 1749\n",
      "\tNegativos: 1669\n",
      "\tTotal: 3418\n"
     ]
    }
   ],
   "source": [
    "def train_test_lists(string, tweets, with_prints):\n",
    "    if with_prints:\n",
    "        print(\"--- \" + string + \" ---\")\n",
    "        print(\"\\nTweets totais : {}\".format(len(tweets)))\n",
    "    \n",
    "    train_perc = 0.8\n",
    "    test_perc = 1 - train_perc\n",
    "    train_size = round(len(tweets)*train_perc)\n",
    "    test_size = round(len(tweets)*test_perc)\n",
    "    train_list = tweets[:train_size]\n",
    "    test_list = tweets[train_size:]\n",
    "\n",
    "    positive_train = 0\n",
    "    negative_train = 0\n",
    "\n",
    "    for tweet in train_list:\n",
    "        if tweet[\"class\"] == \"pos\":\n",
    "            positive_train += 1\n",
    "        else:\n",
    "            negative_train += 1\n",
    "\n",
    "    if with_prints:\n",
    "        print(\"\\nTreino:\")    \n",
    "        print(\"\\tPositivos: {}\".format(positive_train))\n",
    "        print(\"\\tNegativos: {}\".format(negative_train))\n",
    "        print(\"\\tTotal: {}\".format(train_size))\n",
    "        \n",
    "        \n",
    "    positive_test = 0\n",
    "    negative_test = 0\n",
    "\n",
    "    for tweet in test_list:\n",
    "        if tweet[\"class\"] == \"pos\":\n",
    "            positive_test += 1\n",
    "        else:\n",
    "            negative_test += 1\n",
    "    \n",
    "    if with_prints:\n",
    "        print(\"\\nTeste:\")    \n",
    "        print(\"\\tPositivos: {}\".format(positive_test))\n",
    "        print(\"\\tNegativos: {}\".format(negative_test))\n",
    "        print(\"\\tTotal: {}\".format(test_size))\n",
    "    \n",
    "    return train_list, test_list\n",
    "    \n",
    "train_list, test_list = train_test_lists(\"Fase inicial\", tweets, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ferramente utilizada para análise de sentimento diretamente a um texto foi o TextBlob.\n",
    "Para esta classificação inicial foi utilizada a Polarity do TextBlob, tal como o sentimento de cada tweet já fornecido pelo ficheiro \"Tweets_EN_sentiment.json\".\n",
    "Tendo em conta que existe um maior número de tweets considerados positivos, para criar uma maior equidade, os tweets classificados como neutro (polarity = 0 do TextBlob) passam a ser classificados como tweets negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BASELINE ---\n",
      "\n",
      "\n",
      "True positives: 995\n",
      "True Negatives: 560\n",
      "False Positives: 490\n",
      "False Negatives: 1373\n",
      "\n",
      "Tweets Positivos: 1749\n",
      "Tweets Positivos preditados: 1485\n",
      "Tweets Negativos: 1669\n",
      "Tweets Negativos preditados: 1933\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1555\n",
      "\tPredicoes erradas: 1863\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 45.494441193680515\n",
      "\tPrecision: 67.003367003367\n",
      "\tRecall: 42.01858108108108\n",
      "\tF-Measure: 51.64806644173371\n"
     ]
    }
   ],
   "source": [
    "true_positive = 0\n",
    "true_negative = 0 \n",
    "false_positive = 0\n",
    "false_negative = 0\n",
    "real_values = []\n",
    "pred_values = []\n",
    "pos_real = 0\n",
    "pos_pred = 0\n",
    "neg_real = 0\n",
    "neg_pred = 0\n",
    "\n",
    "\n",
    "for tweet in test_list:\n",
    "    polarity = TextBlob(tweet[\"text\"]).sentiment.polarity\n",
    "    sentiment = tweet[\"class\"]\n",
    "      \n",
    "    if sentiment == \"pos\" and polarity > 0:\n",
    "        true_positive += 1\n",
    "    if sentiment == \"neg\" and polarity < 0:\n",
    "        true_negative += 1\n",
    "    if not(sentiment == \"pos\" and polarity > 0) and not(sentiment == \"neg\" and polarity < 0):  \n",
    "        if polarity > 0:\n",
    "            false_positive += 1\n",
    "        else:\n",
    "            false_negative += 1\n",
    "            \n",
    "    if sentiment == 'pos':\n",
    "        real_values.append(1)\n",
    "        pos_real += 1\n",
    "    if sentiment == 'neg':\n",
    "        real_values.append(0)\n",
    "        neg_real += 1\n",
    "    if polarity > 0: \n",
    "        pred_values.append(1)\n",
    "        pos_pred += 1\n",
    "    if polarity <= 0:\n",
    "        pred_values.append(0)\n",
    "        neg_pred += 1\n",
    "\n",
    "        \n",
    "print(\"--- BASELINE ---\\n\\n\")\n",
    "metrics(true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retweets\n",
    "\n",
    "Função que remove todos os tweets repetidos, i.e. Retweets, com a abreviação \"RT\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fase após remoção de Retweets ---\n",
      "\n",
      "Tweets totais : 17013\n",
      "\n",
      "Treino:\n",
      "\tPositivos: 6754\n",
      "\tNegativos: 6856\n",
      "\tTotal: 13610\n",
      "\n",
      "Teste:\n",
      "\tPositivos: 1738\n",
      "\tNegativos: 1665\n",
      "\tTotal: 3403\n"
     ]
    }
   ],
   "source": [
    "def retweets_treatemant(tweets):\n",
    "    for tweet in tweets:\n",
    "        number_tweet = tweet['tweet']\n",
    "        words = TweetTokenizer().tokenize(tweet['text'])\n",
    "        for word in words:\n",
    "            if word == \"RT\":\n",
    "                for i in range(len(tweets)):\n",
    "                    if tweets[i]['tweet'] == number_tweet:\n",
    "                        del tweets[i]\n",
    "                        break\n",
    "                        \n",
    "    train_list, test_list = train_test_lists(\"Fase após remoção de Retweets\", tweets, True)\n",
    "    \n",
    "    return train_list, test_list\n",
    "\n",
    "train_list, test_list = retweets_treatemant(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento dos dados\n",
    "\n",
    "Função para o tratamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_treatment(tweet, with_punctuation, with_stop_words, with_pos_tag):\n",
    "    tweet = abbreviations_treatment(tweet)\n",
    "    tweet = emoticons_treatment(tweet)\n",
    "    tweet = hashtag_treatment(tweet)\n",
    "    tweet = url_treatment(tweet)\n",
    "    tweet = usernames_treatment(tweet)\n",
    "    tweet = numbers_treatment(tweet)\n",
    "    tweet = money_treatment(tweet)\n",
    "    tweet = time_treatment(tweet)\n",
    "    tweet = lower_case_treatment(tweet)\n",
    "    tweet = repetead_characters(tweet)\n",
    "    if with_pos_tag:\n",
    "        with_punctuation = True\n",
    "        with_stop_words = True\n",
    "    if not with_stop_words and not with_punctuation:\n",
    "        tweet = stop_words_treatment(tweet)\n",
    "        tweet = punctuation_symbols_treatment(tweet)\n",
    "        return tweet\n",
    "    if with_stop_words and not with_punctuation:\n",
    "        tweet = punctuation_symbols_treatment(tweet)\n",
    "        return tweet\n",
    "    if not with_stop_words and with_punctuation:\n",
    "        tweet = stop_words_treatment(tweet)\n",
    "        return tweet\n",
    "    if with_stop_words and with_punctuation:\n",
    "        return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags\n",
    "\n",
    "Função que remove o símbolo de hashtag, substituindo pela palavra \"hashtag\", mantendo a palavra.\n",
    "Exemplo: \"#Portugal\" passa a \"hashtag Portugal\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtag(word):\n",
    "    return word.replace(\"#\", \"hashtag \")\n",
    "\n",
    "\n",
    "def hashtag_treatment(tweet):\n",
    "    correct_tweet = tweet\n",
    "    list_matches = [i.group(0) for i in re.finditer(r\"\\S*[#]\\S*\", tweet)]\n",
    "    for word in list_matches:\n",
    "        correct_tweet = correct_tweet.replace(word,remove_hashtag(word))\n",
    "    return correct_tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URL's\n",
    "\n",
    "Função que remove todos os URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_treatment(tweet):\n",
    "    tweet = re.sub(r'''(?:(?:https?|ftp):|(?:https?|ftp):\\/\\/|\\b(?:[a-z\\d]+\\.))(?:(?:[^\\s()<>]+|\\((?:[^\\s()<>]+|(?:\\([^\\s()<>]+\\)))?\\))+(?:\\((?:[^\\s()<>]+|(?:\\(?:[^\\s()<>]+\\)))?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))?''', \"\", tweet)\n",
    "    tweet = re.sub(\" +\",\" \",tweet)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pontuação\n",
    "\n",
    "Função que remove toda a pontuação e símbolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_symbols_treatment(tweet):\n",
    "    tweet = re.sub(r\"[^\\w\\s]\", \" \", tweet)\n",
    "    tweet = re.sub(\" +\",\" \",tweet)\n",
    "    tweet = re.sub(\" +$\",\"\",tweet)\n",
    "    tweet = re.sub(\"^ +\",\"\",tweet)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomes de utilizadores\n",
    "\n",
    "Função que remove todos os nomes de utilizadores que comecem com \"@\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usernames_treatment(tweet):\n",
    "    tweet = re.sub(r\"@+\\w+\", \"\", tweet)\n",
    "    tweet = re.sub(\" +\",\" \",tweet)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minúsculas\n",
    "\n",
    "Função que altera todos os caracteres do tweet para minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_treatment(tweet):\n",
    "    return tweet.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Números\n",
    "\n",
    "Função que remove todos os números, substituindo pela palavra \"number\".\n",
    "Exemplo: \"10\" passa a \"number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_treatment(tweet):\n",
    "    tweet = re.sub(r\"(?<=\\s)\\d+(?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+(?=\\s|$)\", \"number\", tweet)\n",
    "    list_with_punctuation = [i.group(0) for i in re.finditer(r\"(?<=\\s)\\d+[.,;:?!\\-*\\/+=%](?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+[.,;:?!\\-*\\/+=%](?=\\s|$)\", tweet)]\n",
    "    correct_tweet = tweet\n",
    "    for word_punctuation in list_with_punctuation:\n",
    "        punctuation = re.findall(r'[.,;:?!\\-*\\/+=%]', word_punctuation)\n",
    "        correct_tweet = correct_tweet.replace(word_punctuation,\"number\" + punctuation[0])\n",
    "    if re.compile(\"^\\d+[.,]+\\d\\s|^\\d\\s\").match(correct_tweet):\n",
    "        word = re.findall(r'^\\d+[.,]+\\d\\s|^\\d\\s', correct_tweet)\n",
    "        word = word[0].strip()\n",
    "        correct_tweet = correct_tweet.replace(word,\"number\")\n",
    "    if re.compile(\"^\\d+[.,]+\\d+[.,;:?!\\-*\\/+=%]|^\\d+[.,;:?!\\-*\\/+=%]\").match(correct_tweet):\n",
    "        start_with_punctuation = re.findall(r'^\\d+[.,]+\\d+[.,;:?!\\-*\\/+=%]|^\\d+[.,;:?!\\-*\\/+=%]', correct_tweet)\n",
    "        word = re.findall(r'\\d+[.,]+\\d+|\\d+', start_with_punctuation[0])\n",
    "        correct_tweet = correct_tweet.replace(word[0],\"number\")\n",
    "    return correct_tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dinheiro\n",
    "\n",
    "Função que remove referencias a dinheiro, substituindo pela palavra \"money\". Exemplo: \"$10\" passa a \"money\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_treatment(tweet):\n",
    "    tweet = re.sub(r\"(?<=\\s)[$]+\\d+(?=\\s|$)|(?<=\\s)[$]+\\d+[.,]+\\d+(?=\\s|$)|(?<=\\s)\\d+[$]+(?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+[$]+(?=\\s|$)|(?<=\\s)[€]+\\d+(?=\\s|$)|(?<=\\s)[€]+\\d+[.,]+\\d+(?=\\s|$)|(?<=\\s)\\d+[€]+(?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+[€]+(?=\\s|$)\", \"money\", tweet)\n",
    "    list_with_punctuation = [i.group(0) for i in re.finditer(r\"(?<=\\s)[$]+\\d+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)[$]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)\\d+[$]+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+[$]+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)[€]+\\d+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)[€]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)\\d+[€]+[.,;:?!\\-*\\/+](?=\\s|$)|(?<=\\s)\\d+[.,]+\\d+[€]+[.,;:?!\\-*\\/+](?=\\s|$)\", tweet)]\n",
    "    correct_tweet = tweet\n",
    "    for word_punctuation in list_with_punctuation:\n",
    "        punctuation = re.findall(r'[.,;:?!\\-*\\/+]', word_punctuation)\n",
    "        correct_tweet = correct_tweet.replace(word_punctuation,\"money\" + punctuation[0])\n",
    "    if re.compile(\"^[$]+\\d+[.,]+\\d\\s|^\\d+[.,]+\\d+[$]\\s|^[€]+\\d+[.,]+\\d\\s|^\\d+[.,]+\\d+[€]\\s|^[$]+\\d+\\s|^\\d+[$]\\s|^[€]+\\d\\s|^\\d+[€]\\s\").match(correct_tweet):\n",
    "        word = re.findall(r'^[$]+\\d+[.,]+\\d\\s|^\\d+[.,]+\\d+[$]\\s|^[€]+\\d+[.,]+\\d\\s|^\\d+[.,]+\\d+[€]\\s|^[$]+\\d+\\s|^\\d+[$]\\s|^[€]+\\d\\s|^\\d+[€]\\s', correct_tweet)\n",
    "        word = word[0].strip()\n",
    "        correct_tweet = correct_tweet.replace(word,\"money\")\n",
    "    if re.compile(\"^[$]+\\d+[.,;:?!\\-*\\/+]|^[$]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+]|^\\d+[$]+[.,;:?!\\-*\\/+]|^\\d+[.,]+\\d+[$]+[.,;:?!\\-*\\/+]|^[€]+\\d+[.,;:?!\\-*\\/+]|^[€]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+]|^\\d+[€]+[.,;:?!\\-*\\/+]|^\\d+[.,]+\\d+[€]+[.,;:?!\\-*\\/+]\").match(correct_tweet):\n",
    "        start_with_punctuation = re.findall(r'^[$]+\\d+[.,;:?!\\-*\\/+]|^[$]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+]|^\\d+[$]+[.,;:?!\\-*\\/+]|^\\d+[.,]+\\d+[$]+[.,;:?!\\-*\\/+]|^[€]+\\d+[.,;:?!\\-*\\/+]|^[€]+\\d+[.,]+\\d+[.,;:?!\\-*\\/+]|^\\d+[€]+[.,;:?!\\-*\\/+]|^\\d+[.,]+\\d+[€]+[.,;:?!\\-*\\/+]', correct_tweet)\n",
    "        word = re.findall(r'[$]+\\d+[.,]+\\d+|\\d+[.,]+\\d+[$]|[€]+\\d+[.,]+\\d+|\\d+[.,]+\\d+[€]|[$]+\\d+|\\d+[$]|[€]+\\d+|\\d+[€]', start_with_punctuation[0])\n",
    "        correct_tweet = correct_tweet.replace(word[0],\"money\")\n",
    "    return correct_tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempo\n",
    "\n",
    "Função que remove referencias a tempo, substituindo pela palavra \"time\". Exemplo: \"10:10 AM\" passa a \"time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_treatment(tweet):\n",
    "    tweet = re.sub(r\"(?<=\\s)(1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?(?=\\s|$)|(?<=\\s)(1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?(?=\\s|$)\", \"time\", tweet)\n",
    "    list_with_punctuation = [i.group(0) for i in re.finditer(r\"(?<=\\s)(1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+](?=\\s|$)|(?<=\\s)(1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+](?=\\s|$)\", tweet)]\n",
    "    correct_tweet = tweet\n",
    "    for word_punctuation in list_with_punctuation:\n",
    "        punctuation = re.findall(r'[.,;?!\\-*\\/+]', word_punctuation)\n",
    "        correct_tweet = correct_tweet.replace(word_punctuation,\"time\" + punctuation[0])\n",
    "    if re.compile(\"^((1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)\").match(correct_tweet):\n",
    "        word = re.findall(r'^((1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)', correct_tweet)\n",
    "        word = word[0][0].strip()\n",
    "        correct_tweet = correct_tweet.replace(word,\"time\")\n",
    "    if re.compile(\"^((1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)\").match(correct_tweet):\n",
    "        word = re.findall(r'^((1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)', correct_tweet)\n",
    "        word = word[0][0].strip()\n",
    "        correct_tweet = correct_tweet.replace(word,\"time\")\n",
    "    if re.compile(\"^((1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+])\").match(correct_tweet):\n",
    "        start_with_punctuation = re.findall(r'^((1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+])', correct_tweet)\n",
    "        word = re.findall(r'((1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)', start_with_punctuation[0][0])\n",
    "        correct_tweet = correct_tweet.replace(word[0][0],\"time\")\n",
    "    if re.compile(\"^((1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+])\").match(correct_tweet):\n",
    "        start_with_punctuation = re.findall(r'^((1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?[.,;?!\\-*\\/+])', correct_tweet)\n",
    "        word = re.findall(r'((1[0-2]|0?[1-9]):([0-5]?[0-9])(\\s*)(?i)(●?[AP]M)?)', start_with_punctuation[0][0])\n",
    "        correct_tweet = correct_tweet.replace(word[0][0],\"time\")\n",
    "    return correct_tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequência de caracteres repetidos\n",
    "\n",
    "Função que converte uma palavra com mais de 2 caracteres iguais, para a mesma palavra repetida uma vez (sem os caracteres repetidos). Exemplo: \"Golooo\" passa a \"Golo Golo\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repetead_characters(word):\n",
    "    return ''.join(c[0] for c in itertools.groupby(word))\n",
    "\n",
    "\n",
    "def repetead_characters(tweet):\n",
    "    correct_tweet = tweet\n",
    "    list_matches = [i.group(0) for i in re.finditer(r\"\\S*([A-Za-z])(?i)\\1{2,}\\S*\", tweet)]\n",
    "    for word in list_matches:\n",
    "        correct_tweet = correct_tweet.replace(word,remove_repetead_characters(word)+\" \"+remove_repetead_characters(word))\n",
    "    return correct_tweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abreviaturas\n",
    "\n",
    "Função que a partir de um ficherio de formato CSV, delimitado por \",\", com o nome \"abreviations.csv\", converte as abreviações em palavras que cada abreviatura representa. Este ficheiro encontra-se na pasta \"TM_Trabalho_1/Abbreviations\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {}\n",
    "with open('../TM_Trabalho_1/Abbreviations/abbreviations.csv', encoding=\"utf-8\") as csvfile:\n",
    "    for row in csvfile:\n",
    "        row = row.replace(\"\\n\", \"\").replace('''\"''', \"\").split(\",\", 1)\n",
    "        key = row[0]\n",
    "        value = row[1]\n",
    "        abbreviations.update({key: value})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbreviations_treatment(tweet):\n",
    "    correct_tweet = []\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word in abbreviations.keys():\n",
    "            correct_tweet.append(abbreviations.get(word))\n",
    "        else:\n",
    "            correct_tweet.append(word)\n",
    "    return \" \".join(correct_tweet)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoticons\n",
    "\n",
    "Função que a partir de um ficherio de formato CSV, delimitado por \",\", com o nome \"emoticons.csv\", converte os emoticons em palavras que cada emoticon representa. Este ficheiro encontra-se na pasta \"TM_Trabalho_1/Emoticons\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons = {}\n",
    "with open('../TM_Trabalho_1/Emoticons/emoticons.csv', encoding=\"ISO-8859-1\") as csvfile:\n",
    "    for row in csvfile:\n",
    "        row = row.replace(\"\\n\", \"\").split(\",\", 1)\n",
    "        key = row[0]\n",
    "        value = row[1]\n",
    "        emoticons.update({key: value})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoticons_treatment(tweet):\n",
    "    correct_tweet = []\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word in emoticons.keys():\n",
    "            correct_tweet.append(emoticons.get(word))\n",
    "        else:\n",
    "            correct_tweet.append(word)\n",
    "    return \" \".join(correct_tweet)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words\n",
    "\n",
    "Função que remove os stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_treatment(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = TweetTokenizer().tokenize(tweet) \n",
    "    correct_tweet = [] \n",
    "    for word in words: \n",
    "        if word not in stop_words: \n",
    "            correct_tweet.append(word)\n",
    "    return \" \".join(correct_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação de um léxico de sentimentos\n",
    "\n",
    "Nesta fase foi utilizado um classificador de sentimentos, baseado num léxico, neste caso foi utilizado o ficheiro NCR Word-Emotion Association Lexicon (EmoLex), em formato CSV.\n",
    "Deste ficheiro foram utilizados os campos \"English\", \"Positive\" e \"Negative\".\n",
    "Os dados sofreram um tratamento geral, referenciado nas funções anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palavras neutras: 8708\n",
      "Numero de palavras positivas: 2231\n",
      "Numero de palavras negativas: 3243\n",
      "Numero de palavras no lexico: 14182\n"
     ]
    }
   ],
   "source": [
    "lexicon = {}\n",
    "neutral = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "\n",
    "csvfile = open(\"../TM/data/en/NCR-lexicon.csv\", \"r\", encoding=\"utf-8\")\n",
    "csv_reader = csv.DictReader(csvfile, delimiter=\";\")\n",
    "\n",
    "for row in csv_reader:\n",
    "    lexicon.update({row[\"English\"]: (row[\"Positive\"], row[\"Negative\"])})\n",
    "    if (row[\"Positive\"] == \"1\" and row[\"Negative\"] == \"1\") or (row[\"Positive\"] == \"0\" and row[\"Negative\"] == \"0\"):\n",
    "        neutral += 1\n",
    "    if (row[\"Positive\"] == \"1\" and row[\"Negative\"] == \"0\"):\n",
    "        positive += 1\n",
    "    if (row[\"Positive\"] == \"0\" and row[\"Negative\"] == \"1\"):\n",
    "        negative += 1\n",
    "\n",
    "print(\"Numero de palavras neutras: {}\".format(neutral))\n",
    "print(\"Numero de palavras positivas: {}\".format(positive))\n",
    "print(\"Numero de palavras negativas: {}\".format(negative))\n",
    "print(\"Numero de palavras no lexico: {}\".format(len(lexicon)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função auxiliar que verifica quais os métodos a aplicar sem o tratamento da negação, neste caso se é aplicado simplesmente o léxico ou o Lemmatization com o léxico ou o Stemming com o léxico.\n",
    "Recebe os valores inseridos no método \"run_lexicon\" e aplica os métodos solicitados.\n",
    "Devolve tweet_pos_sentiment e tweet_neg_sentiment, que são 2 inteiros, que informam se o tweet tem tendência em ser positivo ou negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimental_lexicon(tweet, with_wordNet, with_stemmer):\n",
    "    tweet = data_treatment(tweet, False, False, False)\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    frequency = FreqDist(words)\n",
    "    tweet_pos_sentiment = 0\n",
    "    tweet_neg_sentiment = 0\n",
    "    \n",
    "    for freq in frequency.most_common():\n",
    "        sentimental_value = freq[1]\n",
    "        lexicon_word = freq[0]\n",
    "        \n",
    "        if not with_wordNet and not with_stemmer:\n",
    "            tweet_pos_sentiment, tweet_neg_sentiment = verify_lexicon_without_neg(lexicon_word, sentimental_value, tweet_pos_sentiment, tweet_neg_sentiment)\n",
    "        if with_wordNet:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            lemmatizer_word = lemmatizer.lemmatize(lexicon_word)\n",
    "            tweet_pos_sentiment, tweet_neg_sentiment = verify_lexicon_without_neg(lemmatizer_word, sentimental_value, tweet_pos_sentiment, tweet_neg_sentiment)\n",
    "        if with_stemmer:\n",
    "            stemmer = PorterStemmer()\n",
    "            stemmer_word = stemmer.stem(lexicon_word)\n",
    "            tweet_pos_sentiment, tweet_neg_sentiment = verify_lexicon_without_neg(stemmer_word, sentimental_value, tweet_pos_sentiment, tweet_neg_sentiment)\n",
    "            \n",
    "    return tweet_pos_sentiment, tweet_neg_sentiment\n",
    "\n",
    "\n",
    "def verify_lexicon_without_neg(word, sentimental_value, tweet_pos_sentiment, tweet_neg_sentiment):\n",
    "    if word in lexicon.keys():\n",
    "        for lexicon_sentiment in lexicon.get(word):\n",
    "            if lexicon.get(word).index(lexicon_sentiment) == 0:\n",
    "                pos_lexicon_sentiment = lexicon_sentiment\n",
    "            if lexicon.get(word).index(lexicon_sentiment) == 1:\n",
    "                neg_lexicon_sentiment = lexicon_sentiment\n",
    "                    \n",
    "                if (pos_lexicon_sentiment == \"1\" and neg_lexicon_sentiment == \"0\") or (pos_lexicon_sentiment == \"1\" and neg_lexicon_sentiment == \"1\"):\n",
    "                    tweet_pos_sentiment += sentimental_value\n",
    "                if (pos_lexicon_sentiment == \"0\" and neg_lexicon_sentiment == \"1\") or (pos_lexicon_sentiment == \"0\" and neg_lexicon_sentiment == \"0\"):\n",
    "                    tweet_neg_sentiment += sentimental_value\n",
    "                    \n",
    "    return tweet_pos_sentiment, tweet_neg_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função auxiliar que verifica quais os métodos a aplicar com o tratamento da negação, neste caso se é aplicado simplesmente o léxico ou o Lemmatization com o léxico ou o Stemming com o léxico. Recebe os valores inseridos no método \"run_lexicon\" e aplica os métodos solicitados. Devolve tweet_pos_sentiment e tweet_neg_sentiment, que são 2 inteiros, que informam se o tweet tem tendência em ser positivo ou negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negation_treatment(tweet, with_wordNet, with_stemmer):\n",
    "    tweet = data_treatment(tweet, True, False, False)\n",
    "    words = TweetTokenizer().tokenize(tweet)\n",
    "    words = util.mark_negation(words)\n",
    "    frequency = FreqDist(words)\n",
    "    tweet_pos_sentiment = 0\n",
    "    tweet_neg_sentiment = 0\n",
    "    \n",
    "    for freq in frequency.most_common():\n",
    "        sentimental_value = freq[1]\n",
    "        lexicon_word = freq[0]\n",
    "        \n",
    "        if \"_NEG\" in lexicon_word:\n",
    "            correct_word = lexicon_word.replace(\"_NEG\",\"\")\n",
    "            correct_word = re.sub(r'[^\\w\\s]', \"\", correct_word)\n",
    "            \n",
    "            if not with_wordNet and not with_stemmer:\n",
    "                tweet_neg_sentiment = verify_lexicon_with_neg(correct_word, sentimental_value, tweet_neg_sentiment)\n",
    "            if with_wordNet:\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "                lemmatizer_word = lemmatizer.lemmatize(correct_word)\n",
    "                tweet_neg_sentiment = verify_lexicon_with_neg(lemmatizer_word, sentimental_value, tweet_neg_sentiment)\n",
    "            if with_stemmer:\n",
    "                stemmer = PorterStemmer()\n",
    "                stemmer_word = stemmer.stem(correct_word)\n",
    "                tweet_neg_sentiment = verify_lexicon_with_neg(stemmer_word, sentimental_value, tweet_neg_sentiment)\n",
    "        else:\n",
    "            tweet_pos_sentiment += sentimental_value\n",
    "            \n",
    "    return tweet_pos_sentiment, tweet_neg_sentiment\n",
    "            \n",
    "            \n",
    "def verify_lexicon_with_neg(word, sentimental_value, tweet_neg_sentiment):\n",
    "    if word in lexicon.keys():\n",
    "        tweet_neg_sentiment += sentimental_value\n",
    "    return tweet_neg_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função principal do léxico que consoante o que for passado como argumento, calcula os valores para as métricas.\n",
    "Para o calculo destes valores, considera-se positivo se a variável tweet_pos_sentiment > tweet_neg_sentiment, e negativo se variável tweet_pos_sentiment <= tweet_neg_sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Léxico sem o tratamento da negação ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Flags not at the start of the expression '(?<=\\\\s)(1[0-2]|0?[1-' (truncated)\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Flags not at the start of the expression '(?<=\\\\s)(1[0-2]|0?[1-' (truncated)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Flags not at the start of the expression '^((1[0-2]|0?[1-9]):(' (truncated)\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Flags not at the start of the expression '^((1[0-2]|0?[1-9]):(' (truncated)\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Flags not at the start of the expression '^((1[0-2]|0?[1-9]):(' (truncated)\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: Flags not at the start of the expression '^((1[0-2]|0?[1-9]):(' (truncated)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Flags not at the start of the expression '\\\\S*([A-Za-z])(?i)\\\\1{' (truncated)\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 773\n",
      "True Negatives: 468\n",
      "False Positives: 413\n",
      "False Negatives: 1749\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 1186\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2217\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1241\n",
      "\tPredicoes erradas: 2162\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 36.467822509550395\n",
      "\tPrecision: 65.17706576728499\n",
      "\tRecall: 30.650277557494054\n",
      "\tF-Measure: 41.693635382955776\n",
      "\n",
      "\n",
      "--- Léxico com WordNet ---\n",
      "\n",
      "True positives: 804\n",
      "True Negatives: 501\n",
      "False Positives: 430\n",
      "False Negatives: 1668\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 1234\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2169\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1305\n",
      "\tPredicoes erradas: 2098\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 38.34851601528064\n",
      "\tPrecision: 65.15397082658023\n",
      "\tRecall: 32.5242718446602\n",
      "\tF-Measure: 43.38909875876957\n",
      "\n",
      "\n",
      "--- Léxico com Stemming ---\n",
      "\n",
      "True positives: 709\n",
      "True Negatives: 447\n",
      "False Positives: 368\n",
      "False Negatives: 1879\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 1077\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2326\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1156\n",
      "\tPredicoes erradas: 2247\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 33.97002644725242\n",
      "\tPrecision: 65.83101207056639\n",
      "\tRecall: 27.39567233384853\n",
      "\tF-Measure: 38.69031377899044\n",
      "\n",
      "\n",
      "--- Léxico com o tratamento da negação ---\n",
      "\n",
      "True positives: 1725\n",
      "True Negatives: 13\n",
      "False Positives: 1617\n",
      "False Negatives: 48\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 3342\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 61\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1738\n",
      "\tPredicoes erradas: 1665\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 51.07258301498677\n",
      "\tPrecision: 51.615798922800714\n",
      "\tRecall: 97.29272419627749\n",
      "\tF-Measure: 67.44868035190615\n",
      "\n",
      "\n",
      "--- Léxico com o tratamento da negação e com WordNet ---\n",
      "\n",
      "True positives: 1724\n",
      "True Negatives: 16\n",
      "False Positives: 1616\n",
      "False Negatives: 47\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 3340\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 63\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1740\n",
      "\tPredicoes erradas: 1663\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 51.13135468704084\n",
      "\tPrecision: 51.616766467065865\n",
      "\tRecall: 97.34613212874082\n",
      "\tF-Measure: 67.46233613774213\n",
      "\n",
      "\n",
      "--- Léxico com o tratamento da negação e com Stemming ---\n",
      "\n",
      "True positives: 1724\n",
      "True Negatives: 14\n",
      "False Positives: 1617\n",
      "False Negatives: 48\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 3341\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 62\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1738\n",
      "\tPredicoes erradas: 1665\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 51.07258301498677\n",
      "\tPrecision: 51.601316970966785\n",
      "\tRecall: 97.29119638826185\n",
      "\tF-Measure: 67.4359475845883\n"
     ]
    }
   ],
   "source": [
    "def run_lexicon(with_wordNet, with_stemmer, with_negation_treatement):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    real_values = []\n",
    "    pred_values = []\n",
    "    pos_real = 0\n",
    "    pos_pred = 0\n",
    "    neg_real = 0\n",
    "    neg_pred = 0\n",
    "    \n",
    "    for tweet in test_list:\n",
    "        sentiment = tweet[\"class\"]\n",
    "        tweet = tweet[\"text\"]\n",
    "        \n",
    "        if sentiment == 'pos': \n",
    "            real_values.append(1)\n",
    "            pos_real += 1\n",
    "        elif sentiment == 'neg': \n",
    "            real_values.append(0)\n",
    "            neg_real += 1\n",
    "            \n",
    "        if not with_negation_treatement:\n",
    "            tweet_pos_sentiment, tweet_neg_sentiment = sentimental_lexicon(tweet, with_wordNet, with_stemmer)\n",
    "        else:\n",
    "            tweet_pos_sentiment, tweet_neg_sentiment = negation_treatment(tweet, with_wordNet, with_stemmer)\n",
    "        \n",
    "        if sentiment == \"pos\" and (tweet_pos_sentiment > tweet_neg_sentiment):\n",
    "            true_positive += 1\n",
    "        if sentiment == \"neg\" and (tweet_pos_sentiment < tweet_neg_sentiment):\n",
    "            true_negative += 1\n",
    "        if not(sentiment == \"pos\" and (tweet_pos_sentiment > tweet_neg_sentiment)) and not(sentiment == \"neg\" and (tweet_pos_sentiment < tweet_neg_sentiment)):\n",
    "            if tweet_pos_sentiment > tweet_neg_sentiment:\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                false_negative += 1  \n",
    "\n",
    "        if tweet_pos_sentiment > tweet_neg_sentiment: \n",
    "            pred_values.append(1)\n",
    "            pos_pred += 1\n",
    "        if tweet_pos_sentiment <= tweet_neg_sentiment: \n",
    "            pred_values.append(0)\n",
    "            neg_pred += 1\n",
    "\n",
    "    metrics(true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred)\n",
    "    \n",
    "    \n",
    "print(\"--- Léxico sem o tratamento da negação ---\\n\")\n",
    "run_lexicon(False, False, False)\n",
    "\n",
    "print(\"\\n\\n--- Léxico com WordNet ---\\n\")\n",
    "run_lexicon(True, False, False)\n",
    "\n",
    "print(\"\\n\\n--- Léxico com Stemming ---\\n\")\n",
    "run_lexicon(False, True, False)\n",
    "\n",
    "print(\"\\n\\n--- Léxico com o tratamento da negação ---\\n\")\n",
    "run_lexicon(False, False, True)\n",
    "\n",
    "print(\"\\n\\n--- Léxico com o tratamento da negação e com WordNet ---\\n\")\n",
    "run_lexicon(True, False, True)\n",
    "\n",
    "print(\"\\n\\n--- Léxico com o tratamento da negação e com Stemming ---\\n\")\n",
    "run_lexicon(False, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizagem automática\n",
    "\n",
    "Funções auxiliares de suporte aos algoritmos de Aprendizagem automática, com tratamento geral aplicado.\n",
    "Os métodos aplicados foram Lemmatization, Stemming, POS-tagging e tratamento da negação.\n",
    "Os algoritmos utilizados foram Naive Bayes, Logistic Regression e SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newdocrep(texts, sentiments, text_sentiments):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    docs = []\n",
    "\n",
    "    for t in texts:\n",
    "        doc = collections.Counter()\n",
    "        for w in tokenizer.tokenize(t):\n",
    "            doc[w] += 1\n",
    "        docs.append(doc)\n",
    "        \n",
    "    voc_length = 3000\n",
    "\n",
    "    tf = collections.Counter()\n",
    "    df = collections.Counter()\n",
    "\n",
    "    for d in docs:\n",
    "        for w in d:\n",
    "            tf[w] += d[w]\n",
    "            df[w] += 1\n",
    "\n",
    "    idfs = {}\n",
    "    for w in tf:\n",
    "        if tf[w] > 2:\n",
    "            idfs[w] = np.log(len(docs)/df[w])\n",
    "\n",
    "    voc = sorted(idfs, key=idfs.get, reverse=True)[:voc_length]\n",
    "    \n",
    "    indice = {}\n",
    "    for i,w in enumerate(sorted(voc)):\n",
    "        indice[w] = i\n",
    "        \n",
    "    docrep = []\n",
    "    for d in docs:\n",
    "        valores = np.zeros([len(voc)])\n",
    "        for w in d:\n",
    "            if w in indice:\n",
    "                valores[ indice[w] ] = d[w]\n",
    "        docrep.append ( valores )\n",
    "        \n",
    "    newdocrep = []\n",
    "    for d,c in zip(docs, text_sentiments):\n",
    "        docwords={}\n",
    "        for w in d:\n",
    "            if w in indice:\n",
    "                docwords[w] = d[w]\n",
    "        newdocrep.append ( (docwords, sentiments[c] ) )\n",
    "    return newdocrep\n",
    "\n",
    "\n",
    "def get_train_test_treatment(tweets, with_pos_tag, with_negation_treatment):\n",
    "    tweets_treated = []\n",
    "    for tweet in tweets:\n",
    "        text = tweet[\"text\"]\n",
    "        sentiment = tweet[\"class\"]\n",
    "        \n",
    "        if with_pos_tag:\n",
    "            correct_tweet = data_treatment(text, True, True, with_pos_tag)\n",
    "        else:\n",
    "            if with_negation_treatment:\n",
    "                correct_tweet = data_treatment(text, True, False, with_pos_tag)\n",
    "            else:\n",
    "                correct_tweet = data_treatment(text, False, False, with_pos_tag)\n",
    "                \n",
    "        tweet_treated = {'text': correct_tweet, 'class': sentiment}\n",
    "        tweets_treated.append(tweet_treated)\n",
    "    train_list, test_list = train_test_lists(\"Após Tratamento dos Tweets\", tweets_treated, False)\n",
    "    \n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def get_values_metrics(sentiment, pred_sentiment, true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred):\n",
    "    if sentiment == \"pos\" and pred_sentiment == 'pos':\n",
    "        true_positive += 1\n",
    "    if sentiment == \"neg\" and pred_sentiment == 'neg':\n",
    "        true_negative += 1\n",
    "    if sentiment == \"neg\" and pred_sentiment == 'pos':\n",
    "        false_positive += 1\n",
    "    if sentiment == \"pos\" and pred_sentiment == 'neg':\n",
    "        false_negative += 1\n",
    "        \n",
    "    if sentiment == 'pos': \n",
    "        real_values.append(1)\n",
    "        pos_real += 1\n",
    "    if sentiment == 'neg': \n",
    "        real_values.append(0)\n",
    "        neg_real += 1\n",
    "            \n",
    "    if pred_sentiment == 'pos': \n",
    "        pred_values.append(1)\n",
    "        pos_pred += 1\n",
    "    if pred_sentiment == 'neg': \n",
    "        pred_values.append(0)\n",
    "        neg_pred += 1\n",
    "        \n",
    "    return true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred\n",
    "\n",
    "\n",
    "def get_classifies(train_list, test_list, with_wordNet, with_stemmer, with_pos, with_negation_treatement, classifier):\n",
    "    sentiments_list = [\"pos\", \"neg\"]\n",
    "    positive_sentiment = sentiments_list[0]\n",
    "    negative_sentiment = sentiments_list[1]\n",
    "    texts_list = []\n",
    "    text_sentiments_list = []\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    real_values = []\n",
    "    pred_values = []\n",
    "    pos_real = 0\n",
    "    pos_pred = 0\n",
    "    neg_real = 0\n",
    "    neg_pred = 0\n",
    "    \n",
    "    for tweet in train_list:\n",
    "        text = tweet[\"text\"]\n",
    "        sentiment = tweet[\"class\"]\n",
    "        \n",
    "        if with_wordNet or with_stemmer or with_pos:\n",
    "            new_text = choose_options(text, with_wordNet, with_stemmer, with_pos, with_negation_treatement)\n",
    "        \n",
    "        if not with_wordNet and not with_stemmer and not with_pos:\n",
    "            new_text = tweet[\"text\"]\n",
    "        \n",
    "        texts_list.append(new_text)\n",
    "        if sentiment == positive_sentiment:\n",
    "            text_sentiments_list.append(0)\n",
    "        if sentiment == negative_sentiment:\n",
    "            text_sentiments_list.append(1)\n",
    "            \n",
    "    newdocrep = get_newdocrep(texts_list, sentiments_list, text_sentiments_list)\n",
    "    \n",
    "    if classifier == 'Naive Bayes':\n",
    "        classifier = naivebayes.NaiveBayesClassifier.train(newdocrep)\n",
    "    if classifier == 'Logistic Regression':\n",
    "        classifier = maxent.MaxentClassifier.train(newdocrep, bernoulli=False, max_iter=1, trace=3)\n",
    "    if classifier == 'SVM':\n",
    "        classifier = nltk.classify.SklearnClassifier(LinearSVC()).train(newdocrep)\n",
    "    \n",
    "    for tweet in test_list:\n",
    "        text = tweet[\"text\"]\n",
    "        sentiment = tweet[\"class\"]\n",
    "        \n",
    "        if with_wordNet or with_stemmer or with_pos:\n",
    "            new_text = choose_options(text, with_wordNet, with_stemmer, with_pos, with_negation_treatement)\n",
    "        \n",
    "        if not with_wordNet and not with_stemmer and not with_pos:\n",
    "            new_text = tweet[\"text\"]\n",
    "        \n",
    "        words = TweetTokenizer().tokenize(new_text)\n",
    "        doc = collections.Counter()\n",
    "        for word in words:\n",
    "            doc[word] += 1\n",
    "    \n",
    "        pred_sentiment = classifier.classify(doc)\n",
    "        \n",
    "        true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred = get_values_metrics(sentiment, pred_sentiment, true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred)\n",
    "        \n",
    "    return true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred\n",
    "        \n",
    "\n",
    "def choose_options(text, with_wordNet, with_stemmer, with_pos_tag, with_negation_treatement):\n",
    "    if with_wordNet:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatizer_list = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "        if with_negation_treatement:\n",
    "            lemmatizer_list = util.mark_negation(lemmatizer_list)\n",
    "            new_text = \" \".join(lemmatizer_list)\n",
    "        else:\n",
    "            new_text = \" \".join(lemmatizer_list)\n",
    "            \n",
    "    if with_stemmer:\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmer_list = [stemmer.stem(word) for word in text.split()]\n",
    "        if with_negation_treatement:\n",
    "            stemmer_list = util.mark_negation(stemmer_list)\n",
    "            new_text = \" \".join(stemmer_list)\n",
    "        else:\n",
    "            new_text = \" \".join(stemmer_list)\n",
    "            \n",
    "    if with_pos_tag:               \n",
    "        if not with_wordNet and not with_stemmer:\n",
    "            words = TweetTokenizer().tokenize(text)\n",
    "            pos_tag_text = nltk.pos_tag(words)\n",
    "            new_text = \"\"\n",
    "        if with_wordNet or with_stemmer:\n",
    "            words = TweetTokenizer().tokenize(new_text)\n",
    "            pos_tag_text = nltk.pos_tag(words)\n",
    "            new_text = \"\"\n",
    "        for word_pos_tag in pos_tag_text:\n",
    "            new_text += \" \" + word_pos_tag[0] + \"_\" + word_pos_tag[1]\n",
    "    \n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função principal da Aprendizagem automática que consoante o que for passado como argumento, calcula os valores para as métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(train_list, test_list, with_treatment, with_wordNet, with_stemmer, with_pos_tag, with_negation_treatment, classifier):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    real_values = []\n",
    "    pred_values = []\n",
    "    pos_real = 0\n",
    "    pos_pred = 0\n",
    "    neg_real = 0\n",
    "    neg_pred = 0\n",
    "    \n",
    "    if with_treatment:\n",
    "        train_list, test_list = get_train_test_treatment(tweets, with_pos_tag, with_negation_treatment)\n",
    "        \n",
    "    true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred = get_classifies(train_list, test_list, with_wordNet, with_stemmer, with_pos_tag, with_negation_treatment, classifier)\n",
    "            \n",
    "    metrics(true_positive, true_negative, false_positive, false_negative, real_values, pred_values, pos_real, pos_pred, neg_real, neg_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** NAIVE BAYES *****\n",
      "\n",
      "--- Sem features ---\n",
      "\n",
      "True positives: 416\n",
      "True Negatives: 1360\n",
      "False Positives: 305\n",
      "False Negatives: 1322\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 721\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2682\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1776\n",
      "\tPredicoes erradas: 1627\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.18924478401411\n",
      "\tPrecision: 57.69764216366158\n",
      "\tRecall: 23.935558112773304\n",
      "\tF-Measure: 33.834892232614884\n",
      "\n",
      "\n",
      "--- Com tratamento geral ---\n",
      "\n",
      "True positives: 437\n",
      "True Negatives: 1347\n",
      "False Positives: 318\n",
      "False Negatives: 1301\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 755\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2648\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1784\n",
      "\tPredicoes erradas: 1619\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.42433147223039\n",
      "\tPrecision: 57.88079470198676\n",
      "\tRecall: 25.143843498273878\n",
      "\tF-Measure: 35.05816285599679\n",
      "\n",
      "\n",
      "--- Com tratamento geral e WordNet ---\n",
      "\n",
      "True positives: 503\n",
      "True Negatives: 1323\n",
      "False Positives: 342\n",
      "False Negatives: 1235\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 845\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2558\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1826\n",
      "\tPredicoes erradas: 1577\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.65853658536586\n",
      "\tPrecision: 59.52662721893491\n",
      "\tRecall: 28.94131185270426\n",
      "\tF-Measure: 38.946960898180414\n",
      "\n",
      "\n",
      "--- Com tratamento geral e Stemming ---\n",
      "\n",
      "True positives: 526\n",
      "True Negatives: 1322\n",
      "False Positives: 343\n",
      "False Negatives: 1212\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 869\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2534\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1848\n",
      "\tPredicoes erradas: 1555\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.30502497796063\n",
      "\tPrecision: 60.52934407364787\n",
      "\tRecall: 30.264672036823935\n",
      "\tF-Measure: 40.35289604909858\n",
      "\n",
      "\n",
      "--- Com tratamento geral e POS-Tagging ---\n",
      "\n",
      "True positives: 422\n",
      "True Negatives: 1351\n",
      "False Positives: 314\n",
      "False Negatives: 1316\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 736\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2667\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1773\n",
      "\tPredicoes erradas: 1630\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.101087275933\n",
      "\tPrecision: 57.33695652173913\n",
      "\tRecall: 24.28078250863061\n",
      "\tF-Measure: 34.11479385610348\n",
      "\n",
      "\n",
      "--- Com tratamento geral e tratamento da negação ---\n",
      "\n",
      "True positives: 442\n",
      "True Negatives: 1348\n",
      "False Positives: 317\n",
      "False Negatives: 1296\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 759\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2644\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1790\n",
      "\tPredicoes erradas: 1613\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.6006464883926\n",
      "\tPrecision: 58.23451910408433\n",
      "\tRecall: 25.431530494821637\n",
      "\tF-Measure: 35.40248297957549\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e POS-Tagging ---\n",
      "\n",
      "True positives: 461\n",
      "True Negatives: 1355\n",
      "False Positives: 310\n",
      "False Negatives: 1277\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 771\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2632\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1816\n",
      "\tPredicoes erradas: 1587\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.36467822509551\n",
      "\tPrecision: 59.79247730220493\n",
      "\tRecall: 26.524741081703105\n",
      "\tF-Measure: 36.74770825029893\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e tratamento da negação ---\n",
      "\n",
      "True positives: 457\n",
      "True Negatives: 1354\n",
      "False Positives: 311\n",
      "False Negatives: 1281\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 768\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2635\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1811\n",
      "\tPredicoes erradas: 1592\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.21774904496033\n",
      "\tPrecision: 59.505208333333336\n",
      "\tRecall: 26.294591484464902\n",
      "\tF-Measure: 36.47246608140463\n",
      "\n",
      "\n",
      "--- Com WordNet ---\n",
      "\n",
      "True positives: 438\n",
      "True Negatives: 1361\n",
      "False Positives: 304\n",
      "False Negatives: 1300\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 742\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2661\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1799\n",
      "\tPredicoes erradas: 1604\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.86511901263591\n",
      "\tPrecision: 59.02964959568733\n",
      "\tRecall: 25.20138089758343\n",
      "\tF-Measure: 35.32258064516129\n",
      "\n",
      "\n",
      "--- Com WordNet e POS-Tagging ---\n",
      "\n",
      "True positives: 414\n",
      "True Negatives: 1370\n",
      "False Positives: 295\n",
      "False Negatives: 1324\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 709\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2694\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1784\n",
      "\tPredicoes erradas: 1619\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.42433147223039\n",
      "\tPrecision: 58.392101551480955\n",
      "\tRecall: 23.8204833141542\n",
      "\tF-Measure: 33.8373518594197\n",
      "\n",
      "\n",
      "--- Com WordNet e tratamento da negação ---\n",
      "\n",
      "True positives: 416\n",
      "True Negatives: 1395\n",
      "False Positives: 270\n",
      "False Negatives: 1322\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 686\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2717\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1811\n",
      "\tPredicoes erradas: 1592\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.21774904496033\n",
      "\tPrecision: 60.64139941690962\n",
      "\tRecall: 23.935558112773304\n",
      "\tF-Measure: 34.32343234323432\n",
      "\n",
      "\n",
      "--- Com Stemming ---\n",
      "\n",
      "True positives: 491\n",
      "True Negatives: 1336\n",
      "False Positives: 329\n",
      "False Negatives: 1247\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 820\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2583\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1827\n",
      "\tPredicoes erradas: 1576\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.687922421392884\n",
      "\tPrecision: 59.8780487804878\n",
      "\tRecall: 28.250863060989644\n",
      "\tF-Measure: 38.38936669272869\n",
      "\n",
      "\n",
      "--- Com Stemming e POS-Tagging ---\n",
      "\n",
      "True positives: 414\n",
      "True Negatives: 1364\n",
      "False Positives: 301\n",
      "False Negatives: 1324\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 715\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2688\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1778\n",
      "\tPredicoes erradas: 1625\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.24801645606818\n",
      "\tPrecision: 57.90209790209791\n",
      "\tRecall: 23.8204833141542\n",
      "\tF-Measure: 33.75458622095393\n",
      "\n",
      "\n",
      "--- Com Stemming e tratamento da negação ---\n",
      "\n",
      "True positives: 435\n",
      "True Negatives: 1371\n",
      "False Positives: 294\n",
      "False Negatives: 1303\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 729\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2674\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1806\n",
      "\tPredicoes erradas: 1597\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.07081986482516\n",
      "\tPrecision: 59.67078189300411\n",
      "\tRecall: 25.028768699654773\n",
      "\tF-Measure: 35.265504661532226\n",
      "\n",
      "\n",
      "--- Com Stemming, POS-Tagging e tratamento da negação ---\n",
      "\n",
      "True positives: 369\n",
      "True Negatives: 1397\n",
      "False Positives: 268\n",
      "False Negatives: 1369\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 637\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2766\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1766\n",
      "\tPredicoes erradas: 1637\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 51.89538642374375\n",
      "\tPrecision: 57.927786499215074\n",
      "\tRecall: 21.231300345224398\n",
      "\tF-Measure: 31.073684210526316\n",
      "\n",
      "\n",
      "--- Com POS-Tagging ---\n",
      "\n",
      "True positives: 406\n",
      "True Negatives: 1384\n",
      "False Positives: 281\n",
      "False Negatives: 1332\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 687\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2716\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1790\n",
      "\tPredicoes erradas: 1613\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.6006464883926\n",
      "\tPrecision: 59.09752547307132\n",
      "\tRecall: 23.36018411967779\n",
      "\tF-Measure: 33.48453608247423\n",
      "\n",
      "\n",
      "--- Com POS-Tagging e tratamento da negação ---\n",
      "\n",
      "True positives: 406\n",
      "True Negatives: 1384\n",
      "False Positives: 281\n",
      "False Negatives: 1332\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 687\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2716\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1790\n",
      "\tPredicoes erradas: 1613\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.6006464883926\n",
      "\tPrecision: 59.09752547307132\n",
      "\tRecall: 23.36018411967779\n",
      "\tF-Measure: 33.48453608247423\n",
      "\n",
      "\n",
      "--- Com Tratamento da negação ---\n",
      "\n",
      "True positives: 416\n",
      "True Negatives: 1360\n",
      "False Positives: 305\n",
      "False Negatives: 1322\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 721\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2682\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1776\n",
      "\tPredicoes erradas: 1627\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 52.18924478401411\n",
      "\tPrecision: 57.69764216366158\n",
      "\tRecall: 23.935558112773304\n",
      "\tF-Measure: 33.834892232614884\n"
     ]
    }
   ],
   "source": [
    "print(\"***** NAIVE BAYES *****\\n\")\n",
    "\n",
    "print(\"--- Sem features ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, True, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, True, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, True, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, True, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming, POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, False, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, True, \"Naive Bayes\")\n",
    "\n",
    "print(\"\\n\\n--- Com Tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, True, \"Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** LOGISTIC REGRESSION *****\n",
      "\n",
      "--- Sem features ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60664        0.639\n",
      "True positives: 1396\n",
      "True Negatives: 450\n",
      "False Positives: 1215\n",
      "False Negatives: 342\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2611\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 792\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1846\n",
      "\tPredicoes erradas: 1557\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.246253305906556\n",
      "\tPrecision: 53.46610494063577\n",
      "\tRecall: 80.32220943613349\n",
      "\tF-Measure: 64.19866636008277\n",
      "\n",
      "\n",
      "--- Com tratamento geral ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60249        0.649\n",
      "True positives: 1326\n",
      "True Negatives: 495\n",
      "False Positives: 1170\n",
      "False Negatives: 412\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2496\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 907\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1821\n",
      "\tPredicoes erradas: 1582\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.51160740523068\n",
      "\tPrecision: 53.125\n",
      "\tRecall: 76.2945914844649\n",
      "\tF-Measure: 62.635805384978745\n",
      "\n",
      "\n",
      "--- Com tratamento geral e WordNet ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.59851        0.655\n",
      "True positives: 1318\n",
      "True Negatives: 569\n",
      "False Positives: 1096\n",
      "False Negatives: 420\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2414\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 989\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1887\n",
      "\tPredicoes erradas: 1516\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.451072583014984\n",
      "\tPrecision: 54.59817729908865\n",
      "\tRecall: 75.8342922899885\n",
      "\tF-Measure: 63.48747591522159\n",
      "\n",
      "\n",
      "--- Com tratamento geral e Stemming ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.59517        0.665\n",
      "True positives: 1251\n",
      "True Negatives: 636\n",
      "False Positives: 1029\n",
      "False Negatives: 487\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2280\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 1123\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1887\n",
      "\tPredicoes erradas: 1516\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.451072583014984\n",
      "\tPrecision: 54.868421052631575\n",
      "\tRecall: 71.97928653624857\n",
      "\tF-Measure: 62.26978596316575\n",
      "\n",
      "\n",
      "--- Com tratamento geral e POS-Tagging ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60609        0.644\n",
      "True positives: 1396\n",
      "True Negatives: 437\n",
      "False Positives: 1228\n",
      "False Negatives: 342\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2624\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 779\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1833\n",
      "\tPredicoes erradas: 1570\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.8642374375551\n",
      "\tPrecision: 53.20121951219512\n",
      "\tRecall: 80.32220943613349\n",
      "\tF-Measure: 64.00733608436497\n",
      "\n",
      "\n",
      "--- Com tratamento geral e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60193        0.649\n",
      "True positives: 1312\n",
      "True Negatives: 506\n",
      "False Positives: 1159\n",
      "False Negatives: 426\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2471\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 932\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1818\n",
      "\tPredicoes erradas: 1585\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.42344989714958\n",
      "\tPrecision: 53.095912585997574\n",
      "\tRecall: 75.4890678941312\n",
      "\tF-Measure: 62.34259919220718\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e POS-Tagging ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60551        0.643\n",
      "True positives: 1381\n",
      "True Negatives: 471\n",
      "False Positives: 1194\n",
      "False Negatives: 357\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2575\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 828\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1852\n",
      "\tPredicoes erradas: 1551\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.42256832206876\n",
      "\tPrecision: 53.631067961165044\n",
      "\tRecall: 79.45914844649022\n",
      "\tF-Measure: 64.03895200556457\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60184        0.651\n",
      "True positives: 1335\n",
      "True Negatives: 538\n",
      "False Positives: 1127\n",
      "False Negatives: 403\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2462\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 941\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1873\n",
      "\tPredicoes erradas: 1530\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.03967087863649\n",
      "\tPrecision: 54.22420796100731\n",
      "\tRecall: 76.81242807825086\n",
      "\tF-Measure: 63.57142857142858\n",
      "\n",
      "\n",
      "--- Com WordNet ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60772        0.637\n",
      "True positives: 1392\n",
      "True Negatives: 452\n",
      "False Positives: 1213\n",
      "False Negatives: 346\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2605\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 798\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1844\n",
      "\tPredicoes erradas: 1559\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.187481633852485\n",
      "\tPrecision: 53.43570057581574\n",
      "\tRecall: 80.09205983889528\n",
      "\tF-Measure: 64.10315450149666\n",
      "\n",
      "\n",
      "--- Com WordNet e POS-Tagging ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60977        0.635\n",
      "True positives: 1416\n",
      "True Negatives: 420\n",
      "False Positives: 1245\n",
      "False Negatives: 322\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2661\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 742\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1836\n",
      "\tPredicoes erradas: 1567\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.95239494563621\n",
      "\tPrecision: 53.213077790304396\n",
      "\tRecall: 81.47295742232451\n",
      "\tF-Measure: 64.37826778813368\n",
      "\n",
      "\n",
      "--- Com WordNet e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.61030        0.639\n",
      "True positives: 1410\n",
      "True Negatives: 432\n",
      "False Positives: 1233\n",
      "False Negatives: 328\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2643\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 760\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1842\n",
      "\tPredicoes erradas: 1561\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.128709961798414\n",
      "\tPrecision: 53.34846765039728\n",
      "\tRecall: 81.12773302646721\n",
      "\tF-Measure: 64.3688655558092\n",
      "\n",
      "\n",
      "--- Com Stemming ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.59759        0.658\n",
      "True positives: 1331\n",
      "True Negatives: 572\n",
      "False Positives: 1093\n",
      "False Negatives: 407\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2424\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 979\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1903\n",
      "\tPredicoes erradas: 1500\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.92124595944754\n",
      "\tPrecision: 54.90924092409241\n",
      "\tRecall: 76.58227848101265\n",
      "\tF-Measure: 63.95963479096587\n",
      "\n",
      "\n",
      "--- Com Stemming e POS-Tagging ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60503        0.643\n",
      "True positives: 1379\n",
      "True Negatives: 469\n",
      "False Positives: 1196\n",
      "False Negatives: 359\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2575\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 828\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1848\n",
      "\tPredicoes erradas: 1555\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.30502497796063\n",
      "\tPrecision: 53.553398058252434\n",
      "\tRecall: 79.34407364787111\n",
      "\tF-Measure: 63.946209135172744\n",
      "\n",
      "\n",
      "--- Com Stemming e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60315        0.649\n",
      "True positives: 1365\n",
      "True Negatives: 526\n",
      "False Positives: 1139\n",
      "False Negatives: 373\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2504\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 899\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1891\n",
      "\tPredicoes erradas: 1512\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.56861592712312\n",
      "\tPrecision: 54.51277955271565\n",
      "\tRecall: 78.5385500575374\n",
      "\tF-Measure: 64.35643564356435\n",
      "\n",
      "\n",
      "--- Com Stemming, POS-Tagging e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60903        0.643\n",
      "True positives: 1397\n",
      "True Negatives: 456\n",
      "False Positives: 1209\n",
      "False Negatives: 341\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2606\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 797\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1853\n",
      "\tPredicoes erradas: 1550\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.451954158095795\n",
      "\tPrecision: 53.60706062931696\n",
      "\tRecall: 80.37974683544303\n",
      "\tF-Measure: 64.31860036832413\n",
      "\n",
      "\n",
      "--- Com POS-Tagging ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.61079        0.636\n",
      "True positives: 1407\n",
      "True Negatives: 416\n",
      "False Positives: 1249\n",
      "False Negatives: 331\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2656\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 747\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1823\n",
      "\tPredicoes erradas: 1580\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.57037907728475\n",
      "\tPrecision: 52.97439759036144\n",
      "\tRecall: 80.95512082853855\n",
      "\tF-Measure: 64.04187528447883\n",
      "\n",
      "\n",
      "--- Com POS-Tagging e tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.61079        0.636\n",
      "True positives: 1407\n",
      "True Negatives: 416\n",
      "False Positives: 1249\n",
      "False Negatives: 331\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2656\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 747\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1823\n",
      "\tPredicoes erradas: 1580\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.57037907728475\n",
      "\tPrecision: 52.97439759036144\n",
      "\tRecall: 80.95512082853855\n",
      "\tF-Measure: 64.04187528447883\n",
      "\n",
      "\n",
      "--- Com Tratamento da negação ---\n",
      "\n",
      "  ==> Training (1 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.496\n",
      "         Final          -0.60664        0.639\n",
      "True positives: 1396\n",
      "True Negatives: 450\n",
      "False Positives: 1215\n",
      "False Negatives: 342\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2611\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 792\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1846\n",
      "\tPredicoes erradas: 1557\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.246253305906556\n",
      "\tPrecision: 53.46610494063577\n",
      "\tRecall: 80.32220943613349\n",
      "\tF-Measure: 64.19866636008277\n"
     ]
    }
   ],
   "source": [
    "print(\"***** LOGISTIC REGRESSION *****\\n\")\n",
    "\n",
    "print(\"--- Sem features ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, True, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, True, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, True, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, True, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming, POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, False, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, True, \"Logistic Regression\")\n",
    "\n",
    "print(\"\\n\\n--- Com Tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, True, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** SVM *****\n",
      "\n",
      "--- Sem features ---\n",
      "\n",
      "True positives: 1395\n",
      "True Negatives: 459\n",
      "False Positives: 1206\n",
      "False Negatives: 343\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2601\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 802\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1854\n",
      "\tPredicoes erradas: 1549\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.481339994122834\n",
      "\tPrecision: 53.63321799307958\n",
      "\tRecall: 80.26467203682394\n",
      "\tF-Measure: 64.30053007605439\n",
      "\n",
      "\n",
      "--- Com tratamento geral ---\n",
      "\n",
      "True positives: 1344\n",
      "True Negatives: 485\n",
      "False Positives: 1180\n",
      "False Negatives: 394\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2524\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 879\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1829\n",
      "\tPredicoes erradas: 1574\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.746694093446955\n",
      "\tPrecision: 53.24881141045958\n",
      "\tRecall: 77.33026467203682\n",
      "\tF-Measure: 63.06898169873298\n",
      "\n",
      "\n",
      "--- Com tratamento geral e WordNet ---\n",
      "\n",
      "True positives: 1318\n",
      "True Negatives: 559\n",
      "False Positives: 1106\n",
      "False Negatives: 420\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2424\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 979\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1877\n",
      "\tPredicoes erradas: 1526\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.157214222744635\n",
      "\tPrecision: 54.37293729372937\n",
      "\tRecall: 75.8342922899885\n",
      "\tF-Measure: 63.33493512734263\n",
      "\n",
      "\n",
      "--- Com tratamento geral e Stemming ---\n",
      "\n",
      "True positives: 1268\n",
      "True Negatives: 598\n",
      "False Positives: 1067\n",
      "False Negatives: 470\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2335\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 1068\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1866\n",
      "\tPredicoes erradas: 1537\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.833970026447254\n",
      "\tPrecision: 54.30406852248394\n",
      "\tRecall: 72.95742232451093\n",
      "\tF-Measure: 62.26368769948441\n",
      "\n",
      "\n",
      "--- Com tratamento geral e POS-Tagging ---\n",
      "\n",
      "True positives: 1376\n",
      "True Negatives: 451\n",
      "False Positives: 1214\n",
      "False Negatives: 362\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2590\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 813\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1827\n",
      "\tPredicoes erradas: 1576\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.687922421392884\n",
      "\tPrecision: 53.12741312741313\n",
      "\tRecall: 79.17146144994246\n",
      "\tF-Measure: 63.58595194085028\n",
      "\n",
      "\n",
      "--- Com tratamento geral e tratamento da negação ---\n",
      "\n",
      "True positives: 1330\n",
      "True Negatives: 486\n",
      "False Positives: 1179\n",
      "False Negatives: 408\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2509\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 894\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1816\n",
      "\tPredicoes erradas: 1587\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.36467822509551\n",
      "\tPrecision: 53.009166998804304\n",
      "\tRecall: 76.52474108170311\n",
      "\tF-Measure: 62.63244643277608\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e POS-Tagging ---\n",
      "\n",
      "True positives: 1369\n",
      "True Negatives: 493\n",
      "False Positives: 1172\n",
      "False Negatives: 369\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2541\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 862\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1862\n",
      "\tPredicoes erradas: 1541\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.71642668233911\n",
      "\tPrecision: 53.876426603699336\n",
      "\tRecall: 78.7686996547756\n",
      "\tF-Measure: 63.9869128301005\n",
      "\n",
      "\n",
      "--- Com tratamento geral, WordNet e tratamento da negação ---\n",
      "\n",
      "True positives: 1334\n",
      "True Negatives: 529\n",
      "False Positives: 1136\n",
      "False Negatives: 404\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2470\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 933\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1863\n",
      "\tPredicoes erradas: 1540\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.745812518366144\n",
      "\tPrecision: 54.0080971659919\n",
      "\tRecall: 76.75489067894131\n",
      "\tF-Measure: 63.40304182509505\n",
      "\n",
      "\n",
      "--- Com WordNet ---\n",
      "\n",
      "True positives: 468\n",
      "True Negatives: 1336\n",
      "False Positives: 329\n",
      "False Negatives: 1270\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 797\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2606\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1804\n",
      "\tPredicoes erradas: 1599\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.01204819277109\n",
      "\tPrecision: 58.72020075282308\n",
      "\tRecall: 26.927502876869962\n",
      "\tF-Measure: 36.92307692307692\n",
      "\n",
      "\n",
      "--- Com WordNet e POS-Tagging ---\n",
      "\n",
      "True positives: 429\n",
      "True Negatives: 1337\n",
      "False Positives: 328\n",
      "False Negatives: 1309\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 757\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 2646\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1766\n",
      "\tPredicoes erradas: 1637\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 51.89538642374375\n",
      "\tPrecision: 56.671070013210034\n",
      "\tRecall: 24.68354430379747\n",
      "\tF-Measure: 34.38877755511022\n",
      "\n",
      "\n",
      "--- Com WordNet e tratamento da negação ---\n",
      "\n",
      "True positives: 1411\n",
      "True Negatives: 441\n",
      "False Positives: 1224\n",
      "False Negatives: 327\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2635\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 768\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1852\n",
      "\tPredicoes erradas: 1551\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.42256832206876\n",
      "\tPrecision: 53.5483870967742\n",
      "\tRecall: 81.18527042577675\n",
      "\tF-Measure: 64.53235764921106\n",
      "\n",
      "\n",
      "--- Com Stemming ---\n",
      "\n",
      "True positives: 1350\n",
      "True Negatives: 539\n",
      "False Positives: 1126\n",
      "False Negatives: 388\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2476\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 927\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1889\n",
      "\tPredicoes erradas: 1514\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 55.509844255069055\n",
      "\tPrecision: 54.523424878836835\n",
      "\tRecall: 77.67548906789413\n",
      "\tF-Measure: 64.07214048410063\n",
      "\n",
      "\n",
      "--- Com Stemming e POS-Tagging ---\n",
      "\n",
      "True positives: 1370\n",
      "True Negatives: 466\n",
      "False Positives: 1199\n",
      "False Negatives: 368\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2569\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 834\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1836\n",
      "\tPredicoes erradas: 1567\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.95239494563621\n",
      "\tPrecision: 53.32814324639937\n",
      "\tRecall: 78.82623705408515\n",
      "\tF-Measure: 63.617367076851636\n",
      "\n",
      "\n",
      "--- Com Stemming e tratamento da negação ---\n",
      "\n",
      "True positives: 1369\n",
      "True Negatives: 502\n",
      "False Positives: 1163\n",
      "False Negatives: 369\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2532\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 871\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1871\n",
      "\tPredicoes erradas: 1532\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.98089920658242\n",
      "\tPrecision: 54.06793048973144\n",
      "\tRecall: 78.7686996547756\n",
      "\tF-Measure: 64.12177985948477\n",
      "\n",
      "\n",
      "--- Com Stemming, POS-Tagging e tratamento da negação ---\n",
      "\n",
      "True positives: 1397\n",
      "True Negatives: 447\n",
      "False Positives: 1218\n",
      "False Negatives: 341\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2615\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 788\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1844\n",
      "\tPredicoes erradas: 1559\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.187481633852485\n",
      "\tPrecision: 53.42256214149139\n",
      "\tRecall: 80.37974683544303\n",
      "\tF-Measure: 64.18561911325521\n",
      "\n",
      "\n",
      "--- Com POS-Tagging ---\n",
      "\n",
      "True positives: 1400\n",
      "True Negatives: 405\n",
      "False Positives: 1260\n",
      "False Negatives: 338\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2660\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 743\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1805\n",
      "\tPredicoes erradas: 1598\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.041434028798115\n",
      "\tPrecision: 52.63157894736842\n",
      "\tRecall: 80.55235903337169\n",
      "\tF-Measure: 63.66530241018645\n",
      "\n",
      "\n",
      "--- Com POS-Tagging e tratamento da negação ---\n",
      "\n",
      "True positives: 1400\n",
      "True Negatives: 405\n",
      "False Positives: 1260\n",
      "False Negatives: 338\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2660\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 743\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1805\n",
      "\tPredicoes erradas: 1598\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 53.041434028798115\n",
      "\tPrecision: 52.63157894736842\n",
      "\tRecall: 80.55235903337169\n",
      "\tF-Measure: 63.66530241018645\n",
      "\n",
      "\n",
      "--- Com Tratamento da negação ---\n",
      "\n",
      "True positives: 1395\n",
      "True Negatives: 459\n",
      "False Positives: 1206\n",
      "False Negatives: 343\n",
      "\n",
      "Tweets Positivos: 1738\n",
      "Tweets Positivos preditados: 2601\n",
      "Tweets Negativos: 1665\n",
      "Tweets Negativos preditados: 802\n",
      "\n",
      "Predicoes:\n",
      "\tPredicoes correctas: 1854\n",
      "\tPredicoes erradas: 1549\n",
      "\n",
      "Metricas:\n",
      "\tAccuracy: 54.481339994122834\n",
      "\tPrecision: 53.63321799307958\n",
      "\tRecall: 80.26467203682394\n",
      "\tF-Measure: 64.30053007605439\n"
     ]
    }
   ],
   "source": [
    "print(\"***** SVM *****\\n\")\n",
    "\n",
    "print(\"--- Sem features ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, True, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, True, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, False, False, False, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, True, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com tratamento geral, WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, True, True, False, False, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, True, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com WordNet e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, True, False, False, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, False, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com Stemming, POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, True, True, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, False, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com POS-Tagging e tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, True, True, \"SVM\")\n",
    "\n",
    "print(\"\\n\\n--- Com Tratamento da negação ---\\n\")\n",
    "run_classifier(train_list, test_list, False, False, False, False, True, \"SVM\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
